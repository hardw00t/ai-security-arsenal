#!/usr/bin/env python3
"""
Data Leakage Scanner
Scans for sensitive data exposure in local storage, logs, and other locations.

Usage:
    python data_leakage_scanner.py --package com.target.app
    python data_leakage_scanner.py -p com.target.app --deep-scan
"""

import argparse
import json
import re
from pathlib import Path
from typing import Callable

from base import (
    BaseWorkflow, Finding, Severity, FindingCategory,
    generate_finding_id, parse_common_args
)


class DataLeakageScanner(BaseWorkflow):
    """Automated data leakage scanner."""

    @property
    def name(self) -> str:
        return "data_leakage_scanner"

    @property
    def description(self) -> str:
        return "Scan for sensitive data leakage in local storage and logs"

    @property
    def steps(self) -> list[tuple[str, Callable]]:
        return [
            ("Initialize Scanner", self.step_initialize),
            ("Scan SharedPreferences", self.step_scan_prefs),
            ("Scan SQLite Databases", self.step_scan_databases),
            ("Scan Logcat Output", self.step_scan_logcat),
            ("Scan External Storage", self.step_scan_external),
            ("Scan Cache Directory", self.step_scan_cache),
            ("Check Clipboard Access", self.step_check_clipboard),
            ("Check Backup Settings", self.step_check_backup),
            ("Scan Network Cache", self.step_scan_network_cache),
            ("Generate Leakage Report", self.step_generate_report),
        ]

    def __init__(self, *args, deep_scan: bool = False, **kwargs):
        super().__init__(*args, **kwargs)
        self.deep_scan = deep_scan
        self.sensitive_data_found: list[dict] = []

    # Sensitive data patterns
    SENSITIVE_PATTERNS = [
        # Credentials
        (r'password["\s:=]+["\']?([^\s"\'<>]{3,})', 'Password', Severity.CRITICAL),
        (r'passwd["\s:=]+["\']?([^\s"\'<>]{3,})', 'Password', Severity.CRITICAL),
        (r'pwd["\s:=]+["\']?([^\s"\'<>]{3,})', 'Password', Severity.HIGH),

        # Tokens & Keys
        (r'api[_-]?key["\s:=]+["\']?([a-zA-Z0-9_-]{16,})', 'API Key', Severity.CRITICAL),
        (r'secret[_-]?key["\s:=]+["\']?([a-zA-Z0-9_-]{16,})', 'Secret Key', Severity.CRITICAL),
        (r'access[_-]?token["\s:=]+["\']?([a-zA-Z0-9._-]{20,})', 'Access Token', Severity.HIGH),
        (r'refresh[_-]?token["\s:=]+["\']?([a-zA-Z0-9._-]{20,})', 'Refresh Token', Severity.HIGH),
        (r'bearer["\s:=]+["\']?([a-zA-Z0-9._-]{20,})', 'Bearer Token', Severity.HIGH),
        (r'auth[_-]?token["\s:=]+["\']?([a-zA-Z0-9._-]{20,})', 'Auth Token', Severity.HIGH),
        (r'session[_-]?id["\s:=]+["\']?([a-zA-Z0-9._-]{16,})', 'Session ID', Severity.HIGH),

        # JWT tokens
        (r'eyJ[a-zA-Z0-9_-]+\.eyJ[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+', 'JWT Token', Severity.HIGH),

        # Personal Identifiable Information (PII)
        (r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', 'Email Address', Severity.MEDIUM),
        (r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', 'Phone Number', Severity.MEDIUM),
        (r'\b\d{3}[-]?\d{2}[-]?\d{4}\b', 'SSN', Severity.CRITICAL),
        (r'\b\d{16}\b', 'Potential Card Number', Severity.HIGH),
        (r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b', 'Card Number', Severity.CRITICAL),

        # Private Keys
        (r'-----BEGIN (?:RSA )?PRIVATE KEY-----', 'Private Key', Severity.CRITICAL),
        (r'-----BEGIN EC PRIVATE KEY-----', 'EC Private Key', Severity.CRITICAL),

        # AWS Credentials
        (r'AKIA[0-9A-Z]{16}', 'AWS Access Key', Severity.CRITICAL),
        (r'aws[_-]?secret[_-]?access[_-]?key["\s:=]+["\']?([a-zA-Z0-9/+=]{40})', 'AWS Secret Key', Severity.CRITICAL),

        # Google/Firebase
        (r'AIza[0-9A-Za-z_-]{35}', 'Google API Key', Severity.HIGH),

        # URLs with credentials
        (r'https?://[^:]+:[^@]+@[^\s]+', 'URL with Credentials', Severity.HIGH),

        # Database connection strings
        (r'jdbc:[a-z]+://[^\s]+', 'Database Connection String', Severity.HIGH),
    ]

    def step_initialize(self) -> None:
        """Initialize the scanner."""
        devices = self.mcp.list_devices()
        if not devices:
            raise RuntimeError("No Android device connected")

        self.progress.info(f"Target package: {self.package}")
        self.progress.info(f"Deep scan: {self.deep_scan}")

    def step_scan_prefs(self) -> None:
        """Scan SharedPreferences for sensitive data."""
        self.progress.info("Scanning SharedPreferences...")

        result = self.mcp.dump_prefs(self.package)

        if not result.get('success'):
            self.progress.warning("Could not access SharedPreferences (root required)")
            return

        content = result.get('output', '')

        for pattern, data_type, severity in self.SENSITIVE_PATTERNS:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                # Deduplicate and limit
                unique_matches = list(set(matches))[:5]

                # Mask sensitive values
                masked = [m[:4] + '*' * (len(m) - 8) + m[-4:] if len(m) > 8 else '****' for m in unique_matches]

                self.sensitive_data_found.append({
                    'type': data_type,
                    'location': 'SharedPreferences',
                    'count': len(matches)
                })

                self.add_finding(Finding(
                    id=generate_finding_id("STORAGE", f"prefs_{data_type.lower().replace(' ', '_')}"),
                    title=f"{data_type} Found in SharedPreferences",
                    severity=severity,
                    category=FindingCategory.STORAGE,
                    description=f"Found {len(matches)} instance(s) of {data_type} in SharedPreferences.",
                    evidence=[f"Pattern: {data_type}", f"Masked samples: {masked}"],
                    affected_component="SharedPreferences",
                    remediation="Use EncryptedSharedPreferences for sensitive data storage.",
                    mastg_id="MASTG-TEST-0001"
                ))

    def step_scan_databases(self) -> None:
        """Scan SQLite databases for sensitive data."""
        self.progress.info("Scanning SQLite databases...")

        result = self.mcp.dump_databases(self.package)

        if not result.get('success'):
            self.progress.warning("Could not access databases (root required)")
            return

        content = result.get('output', '')

        # Check if encrypted
        if 'SQLCipher' not in content:
            # Check for sensitive table names
            sensitive_tables = ['user', 'account', 'credential', 'auth', 'session', 'token', 'password', 'key']
            tables_found = []

            for table in sensitive_tables:
                if re.search(rf'CREATE TABLE.*{table}', content, re.IGNORECASE):
                    tables_found.append(table)

            if tables_found:
                self.add_finding(Finding(
                    id=generate_finding_id("STORAGE", "sensitive_tables"),
                    title="Sensitive Data Tables in Unencrypted Database",
                    severity=Severity.HIGH,
                    category=FindingCategory.STORAGE,
                    description=f"Found potentially sensitive tables in unencrypted SQLite database.",
                    evidence=[f"Tables found: {', '.join(tables_found)}"],
                    affected_component="SQLite Database",
                    remediation="Implement SQLCipher encryption for databases containing sensitive data.",
                    mastg_id="MASTG-TEST-0002"
                ))

        # Scan for sensitive data patterns
        for pattern, data_type, severity in self.SENSITIVE_PATTERNS:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                unique_matches = list(set(matches))[:3]
                masked = [m[:4] + '****' + m[-4:] if len(m) > 8 else '****' for m in unique_matches]

                self.sensitive_data_found.append({
                    'type': data_type,
                    'location': 'SQLite Database',
                    'count': len(matches)
                })

                self.add_finding(Finding(
                    id=generate_finding_id("STORAGE", f"db_{data_type.lower().replace(' ', '_')}"),
                    title=f"{data_type} Found in SQLite Database",
                    severity=severity,
                    category=FindingCategory.STORAGE,
                    description=f"Found {len(matches)} instance(s) of {data_type} in database.",
                    evidence=[f"Masked samples: {masked}"],
                    affected_component="SQLite Database",
                    remediation="Encrypt sensitive database fields or use SQLCipher.",
                    mastg_id="MASTG-TEST-0002"
                ))

    def step_scan_logcat(self) -> None:
        """Scan logcat for sensitive data leakage."""
        self.progress.info("Scanning logcat output...")

        # Clear and get fresh logs
        self.mcp.shell("logcat -c")

        # Get recent logs for the package
        result = self.mcp.get_logcat(self.package, lines=2000)

        if not result.get('success'):
            self.progress.warning("Could not access logcat")
            return

        logs = result.get('output', '')

        for pattern, data_type, severity in self.SENSITIVE_PATTERNS:
            matches = re.findall(pattern, logs, re.IGNORECASE)
            if matches:
                unique_matches = list(set(matches))[:3]
                masked = [m[:4] + '****' if len(m) > 4 else '****' for m in unique_matches]

                # Logging sensitive data is particularly bad
                log_severity = Severity.CRITICAL if severity == Severity.CRITICAL else Severity.HIGH

                self.sensitive_data_found.append({
                    'type': data_type,
                    'location': 'Logcat',
                    'count': len(matches)
                })

                self.add_finding(Finding(
                    id=generate_finding_id("CODE", f"log_{data_type.lower().replace(' ', '_')}"),
                    title=f"{data_type} Leaked in Application Logs",
                    severity=log_severity,
                    category=FindingCategory.CODE,
                    description=f"Application logs contain {data_type}. Logs are accessible to other apps with READ_LOGS permission.",
                    evidence=[f"Found {len(matches)} instances", f"Masked: {masked}"],
                    affected_component="Application Logging",
                    remediation="Remove sensitive data from log statements. Use ProGuard to strip logs in release builds.",
                    mastg_id="MASTG-TEST-0031"
                ))

    def step_scan_external(self) -> None:
        """Scan external storage for sensitive files."""
        self.progress.info("Scanning external storage...")

        external_paths = [
            f"/sdcard/Android/data/{self.package}/",
            f"/storage/emulated/0/Android/data/{self.package}/",
            "/sdcard/Download/",
            "/sdcard/Documents/",
        ]

        for path in external_paths:
            result = self.mcp.shell(f"ls -laR {path} 2>/dev/null")

            if result.get('success') and result.get('output'):
                output = result.get('output', '')

                # Check for sensitive file types
                sensitive_extensions = ['.db', '.sqlite', '.json', '.xml', '.txt', '.log', '.key', '.pem', '.p12', '.jks']
                sensitive_files = []

                for ext in sensitive_extensions:
                    if ext in output.lower():
                        matches = re.findall(rf'\S+{ext}', output, re.IGNORECASE)
                        sensitive_files.extend(matches[:3])

                if sensitive_files:
                    self.add_finding(Finding(
                        id=generate_finding_id("STORAGE", f"external_{path.replace('/', '_')}"),
                        title="Sensitive Files on External Storage",
                        severity=Severity.MEDIUM,
                        category=FindingCategory.STORAGE,
                        description=f"Found potentially sensitive files on world-readable external storage.",
                        evidence=[f"Path: {path}", f"Files: {sensitive_files[:5]}"],
                        affected_component="External Storage",
                        remediation="Store sensitive files only in internal storage with appropriate permissions.",
                        mastg_id="MASTG-TEST-0003"
                    ))

    def step_scan_cache(self) -> None:
        """Scan application cache for sensitive data."""
        self.progress.info("Scanning cache directory...")

        cache_paths = [
            f"/data/data/{self.package}/cache/",
            f"/data/data/{self.package}/app_webview/",
        ]

        for path in cache_paths:
            result = self.mcp.shell(f"su -c 'ls -laR {path}' 2>/dev/null")

            if result.get('success') and result.get('output'):
                output = result.get('output', '')

                # Look for HTTP cache, images, etc.
                if 'http' in output.lower() or 'cache' in output.lower():
                    # Try to read cache contents
                    content_result = self.mcp.shell(f"su -c 'find {path} -type f -exec cat {{}} \\;' 2>/dev/null | head -1000")

                    if content_result.get('success'):
                        cache_content = content_result.get('output', '')

                        for pattern, data_type, severity in self.SENSITIVE_PATTERNS[:5]:  # Top patterns only
                            matches = re.findall(pattern, cache_content, re.IGNORECASE)
                            if matches:
                                self.add_finding(Finding(
                                    id=generate_finding_id("STORAGE", f"cache_{data_type.lower().replace(' ', '_')}"),
                                    title=f"{data_type} Found in Application Cache",
                                    severity=severity,
                                    category=FindingCategory.STORAGE,
                                    description=f"Sensitive data found in application cache files.",
                                    evidence=[f"Location: {path}", f"Data type: {data_type}"],
                                    affected_component="Cache Storage",
                                    remediation="Implement cache encryption and automatic cleanup.",
                                    mastg_id="MASTG-TEST-0004"
                                ))
                                break

    def step_check_clipboard(self) -> None:
        """Check clipboard access and data."""
        self.progress.info("Checking clipboard usage...")

        # Hook clipboard operations
        clipboard_script = """
        Java.perform(function() {
            var ClipboardManager = Java.use('android.content.ClipboardManager');

            ClipboardManager.setPrimaryClip.implementation = function(clip) {
                var text = clip.getItemAt(0).getText();
                if (text) {
                    send({type: 'clipboard_write', length: text.toString().length, preview: text.toString().substring(0, 50)});
                }
                return this.setPrimaryClip(clip);
            };

            ClipboardManager.getPrimaryClip.implementation = function() {
                var clip = this.getPrimaryClip();
                if (clip && clip.getItemCount() > 0) {
                    var text = clip.getItemAt(0).getText();
                    if (text) {
                        send({type: 'clipboard_read', length: text.toString().length});
                    }
                }
                return clip;
            };

            send({type: 'clipboard_hooks_ready'});
        });
        """

        result = self.mcp.start_frida(self.package, clipboard_script)

        if result.get('success'):
            self.add_finding(Finding(
                id=generate_finding_id("STORAGE", "clipboard_monitor"),
                title="Clipboard Usage Monitoring Active",
                severity=Severity.INFO,
                category=FindingCategory.STORAGE,
                description="Clipboard read/write operations are being monitored. Use the app to detect clipboard data exposure.",
                evidence=["ClipboardManager.setPrimaryClip hooked", "ClipboardManager.getPrimaryClip hooked"],
                affected_component="Clipboard",
                remediation="Clear clipboard after use. Don't copy sensitive data to clipboard.",
                mastg_id="MASTG-TEST-0005"
            ))

    def step_check_backup(self) -> None:
        """Check backup settings and data."""
        self.progress.info("Checking backup configuration...")

        app_info = self.mcp.get_app_info(self.package)

        if app_info.get('success'):
            info = app_info.get('output', '')

            # Check allowBackup
            if 'allowBackup=true' in info or 'allowbackup=true' in info.lower():
                self.add_finding(Finding(
                    id=generate_finding_id("STORAGE", "backup_enabled"),
                    title="Application Backup Enabled",
                    severity=Severity.MEDIUM,
                    category=FindingCategory.STORAGE,
                    description="Application allows backup. Sensitive data can be extracted via adb backup.",
                    evidence=["android:allowBackup=\"true\""],
                    affected_component="AndroidManifest.xml",
                    remediation="Set android:allowBackup=\"false\" or implement encrypted BackupAgent.",
                    mastg_id="MASTG-TEST-0006"
                ))

            # Check for fullBackupContent
            if 'fullBackupContent' not in info and 'allowBackup=true' in info.lower():
                self.add_finding(Finding(
                    id=generate_finding_id("STORAGE", "backup_no_rules"),
                    title="No Backup Rules Defined",
                    severity=Severity.LOW,
                    category=FindingCategory.STORAGE,
                    description="Backup is enabled but no fullBackupContent rules exclude sensitive files.",
                    evidence=["allowBackup=true", "No fullBackupContent attribute"],
                    affected_component="AndroidManifest.xml",
                    remediation="Define backup rules in xml/backup_rules.xml to exclude sensitive data.",
                    mastg_id="MASTG-TEST-0006"
                ))

        # Test actual backup
        result = self.mcp.shell(f"adb backup -f /tmp/backup.ab {self.package}")
        self.progress.info("Backup test completed - check /tmp/backup.ab")

    def step_scan_network_cache(self) -> None:
        """Scan network/HTTP cache for sensitive data."""
        self.progress.info("Scanning network cache...")

        cache_paths = [
            f"/data/data/{self.package}/cache/http/",
            f"/data/data/{self.package}/cache/okhttp/",
            f"/data/data/{self.package}/cache/image_manager_disk_cache/",
        ]

        for path in cache_paths:
            result = self.mcp.shell(f"su -c 'ls -la {path}' 2>/dev/null")

            if result.get('success') and result.get('output') and 'No such file' not in result.get('output', ''):
                # HTTP cache exists
                self.add_finding(Finding(
                    id=generate_finding_id("NETWORK", "http_cache"),
                    title="HTTP Response Cache Present",
                    severity=Severity.LOW,
                    category=FindingCategory.NETWORK,
                    description="Application caches HTTP responses locally. May contain sensitive API data.",
                    evidence=[f"Cache path: {path}"],
                    affected_component="HTTP Cache",
                    remediation="Configure Cache-Control headers to prevent caching sensitive responses.",
                    mastg_id="MASTG-TEST-0007"
                ))

                # Try to read cached responses
                if self.deep_scan:
                    content = self.mcp.shell(f"su -c 'cat {path}/*' 2>/dev/null | head -500")
                    if content.get('success'):
                        for pattern, data_type, severity in self.SENSITIVE_PATTERNS[:5]:
                            if re.search(pattern, content.get('output', ''), re.IGNORECASE):
                                self.add_finding(Finding(
                                    id=generate_finding_id("NETWORK", f"cached_{data_type.lower().replace(' ', '_')}"),
                                    title=f"{data_type} Found in HTTP Cache",
                                    severity=severity,
                                    category=FindingCategory.NETWORK,
                                    description=f"Sensitive data cached in HTTP response cache.",
                                    evidence=[f"Data type: {data_type}", f"Location: {path}"],
                                    affected_component="HTTP Cache",
                                    remediation="Use no-store directive for sensitive API responses.",
                                    mastg_id="MASTG-TEST-0007"
                                ))

    def step_generate_report(self) -> None:
        """Generate data leakage report."""
        self.progress.info("Generating data leakage report...")

        # Aggregate by location
        by_location = {}
        for item in self.sensitive_data_found:
            loc = item['location']
            if loc not in by_location:
                by_location[loc] = []
            by_location[loc].append(item['type'])

        report = {
            "scan_type": "Data Leakage Scanner",
            "package": self.package,
            "deep_scan": self.deep_scan,
            "summary": {
                "total_findings": len(self.findings),
                "critical_leaks": len([f for f in self.findings if f.severity == Severity.CRITICAL]),
                "high_risk_leaks": len([f for f in self.findings if f.severity == Severity.HIGH]),
                "data_locations": by_location
            },
            "findings": [f.to_dict() for f in self.findings]
        }

        report_path = self.output_dir / f"{self.package}_data_leakage_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)

        self.progress.info(f"Report saved to: {report_path}")


def main():
    parser = parse_common_args()
    parser.add_argument('--deep-scan', action='store_true', help='Enable deep content scanning')
    args = parser.parse_args()

    workflow = DataLeakageScanner(
        package=args.package,
        output_dir=Path(args.output),
        apk_path=Path(args.apk) if args.apk else None,
        resume=args.resume,
        verbose=args.verbose,
        deep_scan=args.deep_scan
    )

    findings = workflow.run()

    print(f"\n{'='*60}")
    print(f"Data Leakage Scan Complete: {len(findings)} findings")
    print(f"{'='*60}")

    return 0


if __name__ == "__main__":
    exit(main())
